name,web address,description,documentation,endpoints,access mechanisms (protocols and standardised access),serialization formats,common identifiers used for the entities,access and rate limitations,legal rights,scope,taxonomies,TDM,software implementation,legal body,Github/Gitlab,accronim,Namespaces,type,metadata schemas,bulk download
American Archive of Public Broadcasting API,https://github.com/WGBH-MLA/AAPB2#api,"At this moment the API is experimental: No key is required, but we also do not guarantee continued availability.The OAI-PMH feed can be used to harvest records for items available in the Online Reading Room. Please note that only records for items in the Online Reading Room can be harvested this way. We don't support all the verbs, or any formats beyond MODS.","https://github.com/WGBH-MLA/AAPB2#api,https://pbcore.org/","https://americanarchive.org/api.js,https://americanarchive.org/api.xml,https://americanarchive.org/api.json","HTTP,OAI-PMH","XML, JSON, JSONP","id,pbcoreIdentifier",,,broadcasting,,,,,,,,,pbcore,
arXiv API Access,https://info.arxiv.org/help/api/index.html,"The Cornell University e-print arXiv, hosted at arXiv.org, is a document submission and retrieval system that is heavily used by the physics, mathematics and computer science communities. It has become the primary means of communicating cutting-edge manuscripts on current and ongoing research. The primary interface to the arXiv has been human-oriented html web pages. The purpose of the arXiv API is to allow programmatic access to the arXiv's e-print content and metadata. The goal of the interface is to facilitate new and creative use of the the vast body of material on the arXiv by providing a low barrier to entry for application developers.","https://info.arxiv.org/help/api/user-manual.html#Architecture,https://info.arxiv.org/help/oa/index.html,https://info.arxiv.org/help/api/user-manual.html#52-details-of-atom-results-returned",http://export.arxiv.org/api/query,"HTTP,OAI-PMH",XML,"arXiv id,doi","(Rate limits Please note that the following rate limits apply to all of the machines under your control as a whole. You should not attempt to overcome these limits by increasing the number of machines used to make requests. If your use-case requires a higher request rate, please contact our support team.  When using the legacy APIs (including OAI-PMH, RSS, and the arXiv API), make no more than one request every three seconds, and limit requests to a single connection at a time.","https://info.arxiv.org/help/license/index.html
(You are free to use descriptive metadata1 about arXiv e-prints under the terms of the Creative Commons Universal (CC0 1.0) Public Domain Declaration. Metadata are provided by authors, volunteer moderators, arXiv staff, and external partners)[https://info.arxiv.org/help/api/tou.html].",mixed,https://arxiv.org/category_taxonomy,,,,,,atom,,,"https://info.arxiv.org/help/bulk_data.html#harvest,https://info.arxiv.org/help/api/index.html"
Springer Nature API portal,https://dev.springernature.com/,"Springer Nature is a leading global scientific publisher of books and journals, delivering quality content through innovative information products and services. It publishes close to 500 academic and professional society journals. In the science, technology and medicine (STM) sector, the group publishes about 3,000 journals and 13,000 new books a year, as well as the largest STM eBook Collection worldwide. Springer Nature has operations in about 20 countries in Europe, the USA, and Asia, and more than 10,000 employees. The Springer Nature API supports a number of different operations and return formats. These can be controlled by issuing RESTful requests to the API service at http://api.springernature.com","https://dev.springernature.com/restfuloperations,https://dev.springernature.com/adding-constraints,https://dev.springernature.com/documentation","http://api.springernature.com/meta/v2,http://api.springernature.com/openaccess,http://api.springernature.com/metadata",HTTP,"XML, JSON, JSONP","doi,issn,isbn,journalid",https://www.springernature.com/gp/legal/general-terms-of-use/15067848,https://dev.springernature.com/terms-conditions,mixed,,https://www.springernature.com/gp/researchers/text-and-data-mining,,,,,dc,,,
Caselaw Access Project bu Harvard Law School,https://case.law/docs/site_features/api,"The Caselaw Access Project (“CAP”) expands public access to U.S. law. Our goal is to make all published U.S. court decisions freely available to the public online, in a consistent format, digitized from the collection of the Harvard Law School Library. We created CAP's initial collection by digitizing roughly 40 million pages of court decisions contained in roughly 40,000 bound volumes owned by the Harvard Law School Library. The Harvard Law School Collection includes volumes published through 2018. The Harvard Law School Collection was digitized on site at Langdell Hall. Members of our team created metadata for each volume, including a unique barcode, reporter name, title, jurisdiction, publication date and other volume-level information. We then used a high-speed scanner to produce JP2 and TIF images of every page. A vendor then used OCR to extract the text of every case, creating case-level XML files. Key metadata fields, like case name, citation, court and decision date, were corrected for accuracy, while the text of each case was left as raw OCR output. In addition, for cases from volumes not yet in the public domain, our vendor redacted any headnotes.",https://case.law/docs/learning_tracks/APIs/in_depth,https://api.case.law/v1/,HTTP,"XML, JSON","id,courtid",https://case.law/docs/policies/access_limits,https://case.law/docs/policies/access_limits#commercial-licensing,"Social sciences (economy, sociology, psychology, political science)",,,,,,,,,,https://case.law/download/bulk_exports/
Congress.gov API,https://api.congress.gov/,"The beta Congress.gov Application Programming Interface (API) provides a method for Congress and the public to view, retrieve, and re-use machine-readable data from collections available on Congress.gov. This repository contains information on accessing and using the beta Congress.gov API, as well as documentation on available endpoints.","https://github.com/LibraryOfCongress/api.congress.gov/,https://github.com/LibraryOfCongress/api.congress.gov/tree/main/Documentation",https://api.congress.gov/,"HTTP,Swagger","XML, JSON","id,number","The rate limit is set to 1,000 requests per hour.
By default, the API returns 20 results starting with the first record. The 20 results limit can be adjusted up to 250 results. If the limit is adjusted to be greater than 250 results, only 250 results will be returned. The offset, or the starting record, can also be adjusted to be greater than 0.",https://www.loc.gov/legal,mixed,,,CKAN,,https://github.com/LibraryOfCongress/api.congress.gov/,,,,,https://www.govinfo.gov/bulkdata
CORE API,https://core.ac.uk/services/api,"CORE is the world's largest aggregator of open access research papers from repositories and journals. It is a not-for-profit service dedicated to the open access mission. We serve the global network of repositories and journals by increasing the discoverability and reuse of open access content. We provide solutions for content management, discovery and scalable machine access to research. Our services support a wide range of stakeholders, specifically researchers, the general public, academic institutions, developers, funders and companies from a diverse range of sectors including but not limited to innovators, AI technology companies, digital library solutions and pharma. CORE collects, harmonises and enriches large quantities of both metadata and full text research articles from thousands of data providers. On top of this continuously growing corpus, we provide a truly unique API providing real-time machine access to both the metadata and full texts of research papers, enabling developers to build and run innovative applications on top of CORE's content.",https://api.core.ac.uk/docs/v3,,HTTP,JSON,,The API limits are designed to allow reasonable usage and we will change them depending on the load on our servers. You are able to monitor our current api limit by looking for our customised HTTP headers: X-RateLimitRemaining X-RateLimit-Retry-After X-RateLimit-Limit,https://core.ac.uk/terms,mixed,,,,Core,,,,,,
Crossref REST API,https://www.crossref.org/documentation/retrieve-metadata/rest-api/,"Crossref makes research objects easy to find, cite, link, assess, and reuse. We’re a not-for-profit membership organization that exists to make scholarly communications better. Our publicly available REST API exposes the metadata that members deposit with Crossref when they register their content with us. And it’s not just the bibliographic metadata either: funding data, license information, full-text links, ORCID iDs, abstracts, and Crossmark updates are in members’ metadata too. You can search, facet, filter, or sample metadata from thousands of members, and the results are returned in JSON.",https://www.crossref.org/documentation/retrieve-metadata/rest-api/,https://www.crossref.org/documentation/retrieve-metadata/rest-api/,"HTTP, OAI-PMH,Swagger","XML, JSON","doi,datacite,medra,issn,orcid,ror,isbn",There is a maximum row limit of 2000.,https://www.crossref.org/documentation/retrieve-metadata/rest-api/rest-api-metadata-license-information/,mixed,,https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining/,,Crossref,"https://gitlab.com/crossref,https://github.com/CrossRef/rest-api-doc",,"rdf,dc,prism,owl,bibo,foaf",catalog,"csl,schema.org,rdf/xml,turtle",https://academictorrents.com/browse.php?search=Crossref
Dataverse,https://guides.dataverse.org/en/4.6/api/index.html,"We encourage anyone interested in building tools to interoperate with the Dataverse to utilize our APIs. In 4.0, we require to get a token, by simply registering for a Dataverse account, before using our APIs (We are considering making some of the APIs completely public in the future - no token required - if you use it only a few times).",https://guides.dataverse.org/en/6.0/api/index.html,,SWORD,"XML, JSON","id,doi",,https://theopenscholar.com/terms-service,mixed,,,Dataverse,The Institute for Quantitative Social Science,https://github.com/IQSS/dataverse,,,,,
Digital Public Library of America,https://pro.dp.la/developers/api-codex,"The DPLA API is built with the same principles of openness in mind that underlie the broader project it supports. We wish to make the barrier to public access as low as possible, in order to facilitate broader engagement and model accessibility for other institutions similarly situated. All requests are presumed to be ‘friendly’ requests — that is, requests that respect the API’s operating parameters and capacity to deliver data. https://pro.dp.la/developers/object-structure https://pro.dp.la/developers/philosophy","https://pro.dp.la/developers/requests,https://pro.dp.la/developers/responses",https://api.dp.la/v2,,JSON-LD,id,https://pro.dp.la/developers/policies,,CHO (Cultural Heritage Organizations),,,,,https://github.com/dpla,DPLA,"dc, dcterms, dcmitype, dpla, ore, rdf, rdfs, skos, owl,edm",,"map,mods,ore,rdf",https://digitalpubliclibraryofamerica.atlassian.net/wiki/spaces/TECH/pages/5931056/Database+export+files
Europeana API,https://pro.europeana.eu/page/apis,"Europeana APIs allow you to build applications that use the wealth of our collections drawn from the major museums and galleries across Europe. Their scope includes millions of cultural heritage items (from books and paintings to 3D objects and audiovisual material) that celebrate around 4,000 cultural institutions across Europe.
If you want to search Europeana in an simple way (for instance 'give me all results for the word cat), you can then use the Search API. But if you are looking for a way to delve into the structured metadata of Europeana (For instance, to ask the question ""What are all the French 18th-century painters with at least five artworks available through Europeana'), then the SPARQL service is more appropriate. On the other, if you want to get all the metadata associated with a single item, then you can use the Record API. It also possible to obtain a larger amount of metadata and ultimately harvest the complete Europeana repository by using the OAI-PMH Service. Regarding contextual information that is associated to items, we also offer an Entity API that gives you access to information such as Topics, Persons and Places. Lastly, if you want to contribute information about the items that are available on Europeana, you can do it via the Annotations API.","https://pro.europeana.eu/page/apis,https://pro.europeana.eu/page/api-rest-console",https://api.europeana.eu/record/v2/,"HTTP, OAI-PMH, SPARQL","XML, JSONP, JSON-LD, RDF",id,,https://www.europeana.eu/en/rights/terms-of-use,,,,,,https://github.com/europeana,,"dc, dcterms, ore, rdf, skos, owl, cc, foaf, rdaGr2, wgs84, edm",,,
HathiTrust Digital Library,https://www.hathitrust.org/data,"The HathiTrust collection is composed of works from over 50 different libraries  located in the United States and around the world. Bibliographic records represent many different cataloging practices and may even be in different languages.
You can use the HathiTrust APIs to query and retrieve data when you have a known identifier. HathiTrust APIs are not search APIs (e.g., where you use a keyword to search across the collection). You can use the Bibliographic API to do real-time querying against the HathiTrust collection and to retrieve a limited number of bibliographic records. Using a variety of common identifiers (e.g., ISBN, LCCN, OCLC, etc.) as well as HathiTrust identifiers, you can retrieve information about any works associated with those identifiers. The API can provide you with brief or full bibliographic records. The Data API allows you to retrieve page images, OCR text for individual pages, and METS metadata. To retrieve the OCR for more than a few volumes, we recommend that you request a dataset. Restrictions apply.","https://www.hathitrust.org/member-libraries/resources-for-librarians/data-resources/bibliographic-api/,https://www.hathitrust.org/member-libraries/resources-for-librarians/data-resources/oai-feed/,https://www.hathitrust.org/member-libraries/resources-for-librarians/data-resources/research-datasets/",https://catalog.hathitrust.org/api,"HTTP,OAI-PMH","XML, JSON, JSONP","htid,oclc,lccn,issn,isbn,recordnumber","https://www.hathitrust.org/acceptable-use,https://www.hathitrust.org/member-libraries/resources-for-librarians/data-resources/research-datasets/",https://www.hathitrust.org/copyright,,,https://analytics.hathitrust.org/,,,,,,,marc21,https://www.hathitrust.org/member-libraries/resources-for-librarians/data-resources/hathifiles/
IEEE Xplore API,https://developer.ieee.org/getting_started,"Query and retrieve metadata records including abstracts for more than 5 million documents in IEEE Xplore® including Journals, Conference Proceedings, Books, Courses and Standards. The Metadata API supports both simple and Boolean searches.",https://developer.ieee.org/docs,http://ieeexploreapi.ieee.org/api/v1/,HTTP,"XML, JSON","doi,issn,isbn","10	Calls per second
200	Calls per day",https://developer.ieee.org/API_Terms_of_Use2,mixed,,TDM is permitted for non-commercial research purposes only and requires an active IEEE Xplore institutional subscription.,,IEEE,,,,,,
Internet Archive Developer Portal,https://archive.org/developers/index.html,"This portal contains information to help you access data from, integrate with, or contribute to the Internet Archive.","https://archive.org/developers/index-apis.html,https://archive.org/developers/ias3.html,https://archive.org/developers/metadata.html,https://archive.org/developers/internetarchive/cli.html,https://archive.org/developers/internetarchive/cli.html#metadata,https://programminghistorian.org/en/lessons/data-mining-the-internet-archive",https://archive.org/developers/internetarchive/cli.html#search,"HTTP,SOAP","XML, JSON","ark,isbn,issn,lccn,oclc",https://archive.org/developers/ias3.html#use-limits,https://archive.org/about/terms.php,mixed,,,,,"https://github.com/jjjake/internetarchive,https://github.com/john-corcoran/internetarchive-downloader",,,,marc,https://github.com/john-corcoran/internetarchive-downloader
The Lens,https://docs.api.lens.org/index.html,"With over 20 years of development, supported by prominent philanthropic organizations, The Lens ingests, cleans, aggregates, normalizes and serves over 225+ million scholarly works, 127+ million global patent records, and more than 370+ million patent sequences, with rich metadata including the people and institutions that generate this knowledge and the linkages between them, drawn from diverse data sources.",https://docs.api.lens.org/index.html,https://api.lens.org/swagger-ui.html,"HTTP, Swagger",JSON,"doi,pmid,pmcid,magid,coreid,openalex",,https://about.lens.org/lens-api-terms-of-use/,mixed,,,,,https://github.com/cambialens/lens-api-doc,,,Agregator,,https://support.lens.org/knowledge-base/bulk-data-downloads/
JSON/YAML for LoC.gov,https://loc.gov/apis,"The Library of Congress makes three different loc.gov APIs available to the public:
JSON/YAML for loc.gov: The loc.gov API provides structured data about Library of Congress collections. The API was originally designed to power the loc.gov website, but in addition to providing HTML for the website it can provide a wealth of information in JSON format. The loc.gov API provides structured data about Library of Congress collections in the JSON and YAML formats. Software programs routinely access the JSON API to keep the loc.gov website updated as new digital content is added to the Library's collections.",https://www.loc.gov/apis/json-and-yaml/,,HTTP,"JSON, YAML",,https://www.loc.gov/apis/json-and-yaml/working-within-limits,https://www.loc.gov/legal/,CHO (Cultural Heritage Organizations),,,,Library of Congress,,,dc,,"marc,mods","https://www.loc.gov/collections/selected-datasets/about-this-collection/,https://www.loc.gov/collections/selected-datasets/"
Chronicling America,https://chroniclingamerica.loc.gov/about/api/,"Search America's historic newspaper pages from 1777-1963 or use the U.S. Newspaper Directory to find information about American newspapers published between 1690-present. Chronicling America is sponsored jointly by the National Endowment for the Humanities and the Library of Congress. Together they make up an extensive application programming interface (API) which you can use to explore all of our data in many ways. The directory of newspaper titles contains nearly 140,000 records of newspapers and libraries that hold copies of these newspapers. The title records are based on MARC data gathered and enhanced as part of the NDNP program.",https://chroniclingamerica.loc.gov/about/api/,,HTTP,"JSON, JSONP, RDF",lccn,,https://www.loc.gov/legal/,CHO (Cultural Heritage Organizations),,,,,"https://github.com/LibraryofCongress/chronam,https://github.com/LibraryOfCongress/data-exploration",,"dc, dcterms, ore, owl",,,"https://chroniclingamerica.loc.gov/data/batches/,https://chroniclingamerica.loc.gov/ocr/"
The New York Times Developer Network,https://developer.nytimes.com/apis,"Our APIs (Application Programming Interfaces) allow you to programmatically access New York Times data for use in your own applications. Our goal is to facilitate a wide range of uses, from custom link lists to complex visualizations. Why just read the news when you can hack it? NYT currently has ten public APIs: Archive, Article Search, Books, Most Popular, Semantic, Times Newswire, TimesTags, and Top Stories.",https://developer.nytimes.com/apis,"https://api.nytimes.com/svc/search/v2/,https://api.nytimes.com/svc/books/v3/",HTTP,JSON,"url,usbn13,uuid","4,000 requests per day and 10 requests per minute. You should sleep 6 seconds between calls to avoid hitting the per minute rate limit.",https://developer.nytimes.com/terms,mixed,,https://nytlicensing.com/data-solutions/,,The New York Times,,,,,,
OECD data for developers,https://data.oecd.org/api/,"The OECD has application programming interfaces (APIs) that provide access to datasets in the catalogue of OECD databases. The APIs allow you to query the data in several ways, using parameters to specify your request so that you can create innovative software applications which use OECD datasets. The APIs are available in JSON and XML formats.","https://data.oecd.org/api/sdmx-json-documentation/,https://github.com/sdmx-twg/sdmx-rest/blob/v2.0.0/doc/data.md","http://stats.oecd.org/SDMX-JSON/data/,https://sdmx.oecd.org/public/rest/v2/data/dataflow/",HTTP,"XML, JSON,CSV","id,doi",,https://www.oecd.org/termsandconditions/,,,,,,,,,,"SDMX-ML,SDMX-JSON",
Open Researcher and Contributor ID,https://info.orcid.org/documentation/features/public-api/,"ORCID offers a public API that allows organizations that are not ORCID members to connect their systems and applications to the ORCID registry with machine-to-machine communications. The API is a restful API and supports both XML and JSON.
Member organizations can use the member API to request and obtain permission to read trusted data on their researchers ORCID records. The organization can ask researchers to grant them specific permission to read limited-access information at the same time that they request permission to collect ORCID iD’s. Once the researcher has granted permission, the trusted organization will be able to use the member API to read the ORCID record and read information that the researcher has set as visible to trusted parties in addition to the information set as visible to everyone.","https://github.com/ORCID/ORCID-Source/tree/development/orcid-api-web/tutorial,https://github.com/ORCID/ORCID-Source/tree/main/orcid-api-web#endpoints,https://github.com/ORCID/orcid-model/blob/master/src/main/resources/record_3.0/README.md",https://api.sandbox.orcid.org/v3.0,HTTP,"XML, JSON, CSV",orcid,https://github.com/ORCID/ORCID-Source/tree/development/orcid-api-web#api-limits,https://info.orcid.org/terms-of-use/,mixed,,,,,https://github.com/ORCID/ORCID-Source/tree/development/orcid-api-web/tutorial,ORCID,,,,
Joint Research Centre Data Catalogue,https://data.jrc.ec.europa.eu/,"The Joint Research Centre (JRC) is the European Commission's in-house science service which employs scientists to carry out research in order to provide independent scientific advice and support to policies of the European Union.
A dedicated JRC Data Policy was prepared to complement the JRC Policy on Open Access to Scientific Publications and Supporting Guidance, and to promote open access to research data in the context of Horizon 2020. One way to access the data is to use the REST API. Most of the portal core functionalities are available through the application programming interface (API), which encompasses most of what you can do with the web interface. The information retrieved can then be used by an external code to transform, update or reference and provide new input for further calls to the API.","https://data.jrc.ec.europa.eu/about#services,https://data.jrc.ec.europa.eu/docs/index.html",https://data.jrc.ec.europa.eu/docs/index.html,"HTTP, Swagger","XML,JSON",id,,https://data.jrc.ec.europa.eu/about,mixed,,,CKAN,Joint Research Centre of the European Commission,,,"dc,foaf,og,vcard,owl",Agregator,"DCAT-AP,RDF",
data.europa.eu - The official portal for European data,https://data.europa.eu/api/hub/search/,"The portal is a central point of access to European open data from international, European Union, national, regional, local and geodata portals. It consolidates the former EU Open Data Portal and the European Data Portal. The metadata catalogue of datasets can be explored through a search engine (data tab), through a map for geospatial data or through a SPARQL endpoint and API endpoint. The 'data providers' (EU institutions, agencies and EU bodies, Member States, and other European countries) are autonomous in publishing their metadata (which gives you access to their data) in data.europa.eu. The portal also publishes datasets of other European countries and organisations beyond the EU. The portal is updated when new datasets and content are available.",,,"HTTP, OAI-PMH, SPARQL","JSON, JSON-LD",,,"The choice of a license should be discussed with the data provider. Following the EC decision from 2019, Directorates-General should try to publish their reusable content under CC BY, but for publications ordered before 2019 things are not as clear. In any case it's their decision.",mixed,,,CKAN,Publications Office of the European Union,https://gitlab.com/european-data-portal,,,Agregator,,
Elsevier Research Products APIs,https://dev.elsevier.com/,"Elsevier's RESTful APIs provide access to content from platforms like ScienceDirect, Scopus and Engineering Village for various use cases. These use cases are governed by the policies outlined on this page. These policies define how clients are allowed to use content retrieved through Elsevier's APIs.","https://dev.elsevier.com/interactive.html,https://dev.elsevier.com/api_docs.html,https://dev.elsevier.com/support.html","https://api.elsevier.com/content/search/sciencedirect,https://api.elsevier.com/content/search/scopus","HTTP, Swagger","XML, JSON","doi,pii,eid",https://dev.elsevier.com/api_service_agreement.html,https://www.elsevier.com/legal/elsevier-website-terms-and-conditions,"Natural sciences (chemistry, earth sciences, physics, cosmology, biology, paleontology), Social sciences (economy, sociology, psychology, political science, law), Humanities (linguistics, philology, art, literature, history), Applied science (medical science, informatics, space)",,https://dev.elsevier.com/tdm_service.html,,,https://github.com/ElsevierDev,,"prism,dc",,,
F1000Research ,https://f1000research.com/developers,"This API allows anyone to download the XML and PDF of specific articles as well as to download links to the XML of the entire corpus of articles. The content is indexed using Apache Solr, which is open-source software that allows simple queries to be built in order to search and retrieve the content required. Each article is assigned a unique DOI that can be resolved at doi.org. An example of a DOI for an F1000Research article is 10.12688/f1000research.13256.2. Solr queries will return the DOIs of articles that match the search. See below for details of how to build a Solr query, and the parameters and terms that you can use to refine your search.",https://f1000research.com/developers,,HTTP,XML,"doi,issn,orcid","Limitations on requests
Frequency of requests Please note, user can only make 100 requests per 60 seconds; if the requests exceed this, an unauthorized status 401 will be returned.
Number of results per request. There is a limit of 100 results per request.",© 2012-2023 F1000 Research Ltd.,mixed,,,,,,,,Agregator,,
Clarivate Developer Portal,https://developer.clarivate.com/,"The Web of Science™ Journals API provides REST-based programmatic access to the Journal Citation Reports™, with JSON output format and advanced search and filter capabilities. Journal Citation Reports is the only journal report of its kind that is both complete and editorially selective; it contains all the data required to understand the components that index the value and impact of each journal.The structured data are curated by a global team of experts who continuously evaluate and select the collections of journals, books, and conference proceedings covered in the Web of Science Core Collection to ensure accuracy in evaluating journal impact. These expert insights enable you to explore the key drivers of a journal's value, making better use of the vast body of data and metrics available in the Journal Citation Reports, including the Journal Impact Factor (JIF) and other ranking analysis.","https://developer.clarivate.com/apis,https://webofscience.help.clarivate.com/en-us/Content/home.htm,https://api.clarivate.com/swagger-ui/?url=https%3A%2F%2Fdeveloper.clarivate.com%2Fapis%2Fwos-starter%2Fswagger,https://clarivate.libguides.com/home","https://wos-api.clarivate.com/api/woslite,https://api.clarivate.com/apis/wos-starter/v1","HTTP, Swagger","XML, JSON","uid,doi,issn,isbn,pubmedid",https://developer.clarivate.com/content/api-usage/view,https://clarivate.com/legal-center/terms-of-business/,mixed,,,,,https://github.com/clarivate/wosjournals-javascript-client,,,Metacatalog,,
Wiley Online Library,https://olabout.wiley.com/WileyCDA/Section/id-829771.html,"Wiley is keen to encourage innovative uses of the content we publish, and supports customers who wish to perform text and data mining (TDM) on Wiley content. We are committed to developing tools and services that will enable subscribers to carry out TDM in the most efficient and effective manner, as well as to providing straightforward access to content for TDM purposes.
Academic subscribers can perform TDM under license (or in accordance with statutory rights in the UK) on subscribed content for non-commercial purposes at no extra cost.
Corporate subscribers should contact their account manager to discuss options available for content access and delivery.
In order to maximize platform stability and security for all users, we ask that access to content for TDM purposes takes place through an approved API service, rather than through crawling Wiley Online Library. Our preferred access solution for TDM is the Crossref Text and Data Mining Service. Academic subscribers can register with Crossref and will then be able to access subscribed content once they have accepted the Wiley click-through TDM license and received an API token.
Further details on the Crossref Text and Data Mining Service are available at http://tdmsupport.crossref.org/researchers/.",,https://api.wiley.com/onlinelibrary/tdm/v1,HTTP,"XML, JSON",doi,,https://olabout.wiley.com/WileyCDA/Section/id-826542.html,https://olabout.wiley.com/WileyCDA/Section/id-829771.html,,https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining-for-researchers/,,Wiley,,,,,,
Crossref Unified Resource API,https://www.crossref.org/services/metadata-retrieval,The Crossref REST API is one of a variety of tools and APIs that allow anybody to search and reuse our members' metadata in sophisticated ways.,"https://api.crossref.org/swagger-ui/index.html,https://www.crossref.org/documentation/retrieve-metadata/xml-api/",https://api.crossref.org/works,"HTTP, OAI-PMH, Swagger","XML, JSON","doi,isbn,issn,orcid",50 requests a second,"https://www.crossref.org/documentation/metadata-plus/#00342
Service level agreement (SLA) Crossref will maintain an aggregated, average uptime for all of the interfaces that together comprise the Crossref Metadata Service of 99.5%, reported on a monthly basis. Crossref will provide technical support to Subscriber through Crossref’s existing support channels as requested by Subscriber, and will provide a response within one (1) business day to support requests received during normal working hours in the United States and the United Kingdom. “Business days” do not include weekends or legal holidays in the United States and the United Kingdom. “Response” means that support requests will be acknowledged. The time required for resolution will depend upon the nature of the request.
Agreement and fees for Metadata Plus Learn more about the Metadata Plus service agreement, and fees and pricing tiers for Metadata Plus.",mixed,,https://www.crossref.org/documentation/retrieve-metadata/rest-api/text-and-data-mining/,,Crossref,,,,Agregator,,
Data.Bibliotheken.nl,http://data.bibliotheken.nl/,"The KB's extensive digital collections make it possible to use software to analyse large quantities of text, structured data or images from several centuries, in search of historical patterns or breaks",https://www.kb.nl/onderzoeken-vinden/voor-onderzoekers/dataservices-apis-en-downloads,,"HTTP, SPARQL",,id,,CC0,CHO (Cultural Heritage Organizations),,,,Koninklijke Bibliotheek,,,"rdf,owl",Agregator,,
BnF API et jeux de données,https://api.bnf.fr/,"Le portail BnF API et jeux de données décrit et documente l'ensemble des API (Application Programming Interface, interface de programmation applicative) qui permettent d’interroger et de récupérer les métadonnées des catalogues et les collections numérisées de la BnF (notamment BnF catalogue général, data.bnf.fr, Gallica). Pour faciliter l’accès aux données et leur utilisation, des jeux de données (images et textes, métadonnées, statistiques) sont directement téléchargeables via le portail.(https://www.bnf.fr/fr/portail-bnf-api-et-jeux-de-donnees).","https://api.bnf.fr/fr/utiliser-les-api-de-gallica-lexemple-du-rapport-de-recherche,https://api.bnf.fr/api-gallica-de-recherche",,"OAI-PMH, SPARQL, SRU, IIIF","XML,JSON, JSON-LD, RDF","ark,uri",https://api.bnf.fr/fr/cgu,Licence ouverte de l’état - https://www.etalab.gouv.fr/licence-ouverte-open-licence/,CHO (Cultural Heritage Organizations),,,,Bibliothèque nationale de France,,,"dcterms, rdf, rdfs, skos, foaf, rdaGr2,srw,dc,onix","Metacatalog, Agregator",,
Open Data at the BnL,https://data.bnl.lu/apis/,"In addition to raw datasets, the National Library of Luxembourg offers various web services, Application Programming Interfaces (APIs) and other interfaces to access and query data from its systems. The BnL is the coordinator of the bibnet.lu national network of Luxembourgish libraries. The InfoBib API offers information about each library in the network: address and opening times, contact information, access conditions etc. The BnL exposes structured metadata in the collective catalogue of the bibnet.lu library network using the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH). The OAI-PMH protocol is a means of exchanging metadata over the Internet between several institutions.",,,OAI-PMH,XML,,,https://data.bnl.lu/data/rights/,"CHO (Cultural Heritage Organizations), mixed",,,,Bibliothèque nationale du Luxembourg,https://github.com/natliblux,,"dc, dcterms",Metacatalog,,
German National Library catalogues,https://www.dnb.de/EN/oai,"In order to use OAI to compare data between the German National Library and a service provider, the service provider must have implemented an OAI harvester. The OAI harvester calls itself repeatedly in a continuous loop.",https://www.dnb.de/EN/oai,https://services.dnb.de/oai/repository,"OAI-PMH, SRU","XML, RDF",,"SRU:
Standard (default): 10 data records per response Maximum: 100 data records per reply if ...&maximumRecords=100 specified (possible values 1 to 100)
Call of further data records: ...&startRecord=101 (possible values 1 to 99,000)","All bibliographic data from the German National Library, the German Union Catalogue of Serials (ZDB), the metadata of the ISIL and library code list and the authority data from the Integrated Authority File (GND) is available free of charge for general re-use under Creative Commons Zero terms (CC0 1.0).
Most of the holding data in the German Union Catalogue of Serials (ZDB) is also free for general re-use under CC0 1.0. A corresponding tag is incorporated into the record itself.
The metadata and online interfaces are provided with no guarantee that they will be continuous, punctual, error-free or complete or that they do not violate third-party rights (e.g. personal rights and copyright).",CHO (Cultural Heritage Organizations),,,,Deutsche Nationalbibliothek,,,dcterms,Metacatalog,,
Data Catalog of the National Library of Finland,https://www.kiwi.fi/display/Datacatalog/APIs,"Access open data sources maintained by the National Library of Finland
http://data.nationallibrary.fi/","https://www.kiwi.fi/display/Datacatalog/APIs,https://api.finna.fi/swagger-ui/?url=%2Fapi%2Fv1%3Fswagger",https://www.doria.fi/open-search,"HTTP, OAI-PMH, SPARQL, Swagger, SRU","XML,JSON, JSON-LD, RDF",urn,,,CHO (Cultural Heritage Organizations),,,,National Library of Finland,,,,Metacatalog,,https://data.nationallibrary.fi/download/
MUSEUMS VICTORIA COLLECTIONS,https://collections.museumsvictoria.com.au/developers,"This site allows users to explore the natural sciences and humanities collections of Museums Victoria in Australia, featuring collections of zoology, geology, palaeontology, history, First Peoples and technology. Over 1.15 million records were presented at launch in 2015, accompanied by over 150,000 images. Our API is a set of methods based on restful ideas over HTTP. At this time it only supports the GET verb and responses are in JSON only.",https://collections.museumsvictoria.com.au/developers,https://collections.museumsvictoria.com.au/api,HTTP,JSON,id,,"Open access to data, text content and images.We wish to encourage reuse and sharing of content.
The elements of each record that are defined as data carry a Creative Commons Zero (CC0) license. All the text content and information written by curators, collection managers, and others is released under a Creative Commons Attribution 4.0 International (CC- BY) licence.
Images, sounds and audio-visual material are licensed separately to text. We apply open licenses wherever possible, including marking images as Public Domain as applicable. You will find over 100,000 openly licensed and public domain images in this site.",,,,,,https://github.com/museumsvictoria/collections-online,,,Metacatalog,,
Kungliga biblioteket Library Database API,tveckling/libris/att-anvanda-librisdata/biblioteksdatabasens-api.html,"All data contained in the database is available through the API. However, contact information data requires sending with an API key as an extra header in the call. Contact Libris customer service if you need an API.","https://bibliometri.swepub.kb.se/api/v1/apidocs/,https://bibliometri.swepub.kb.se/api/v1/apidocs/?urls.primaryName=Info%20API",https://bibliometri.swepub.kb.se/api/v1/apidocs/,"HTTP, OAI-PMH, Swagger, SRU","JSON, RDF, RIS",id,,"Swedish national bibliography and Swedish authority posts have been freely available since the summer of 2011 without restrictions. The license form is Creative Commons level 0.
Swedish national bibliography and Swedish authority posts are a subset of Libris. The goal is to make the entire Libris database available under an open license.
The data contains links to Wikipedia, DBPedia, LC Authorities ( name and subject word ) as well VIAF. VIAF was also used to find some of the links.
There are two ways to access this data, either in Atom format or through the OAI-PMH protocol.",,,,,Kungliga Biblioteket,,LIBRIS,dc,Metacatalog,mods,https://bibliometri.swepub.kb.se/bibliometrics/datadump
The OpenAIRE APIs,https://graph.openaire.eu/develop/,"The OpenAIRE Graph includes metadata and links between scientific products (e.g. literature, datasets, software, and ""other research products""), organizations, funders, funding streams, projects, communities, and (provenance) data sources - the details of the graph data model can be found in Zenodo.org. The Graph is available and obtained as an aggregation of the metadata and links collected from ~70.000 trusted sources, further enriched with metadata and links provided by:
OpenAIRE end-users, e.g. researchers, project administrators, data curators providing links from scientific products to projects, funders, communities, or other products;OpenAIRE Full-text mining algorithms over around ~10Mi Open Access article full-texts;
Research infrastructure scholarly services, bridged to the graph via OpenAIRE, exposing metadata of products such as research workflows, experiments, research objects, software, etc. The Broker Service is available to use via the OpenAIRE Content Provider Dashboard. Thanks to the Broker, repositories, publishers or aggregators can exchange metadata and enrich their local metadata collection by subscribing to notifications of different types. The Broker is able to notify providers when the OpenAIRE Graph contains information that is not available in the original collection of the data source.",https://graph.openaire.eu/develop/api.html,http://api.openaire.eu/search,"HTTP, Swagger",XML,"doi,orcid,id",0,"OpenAIRE Graph license is CC-BY: the records returned by the service can be freely re-used by commercial and non-commercial partners under CC-BY license, hence as long as OpenAIRE is acknowledged as a content provider.","Natural sciences (chemistry, earth sciences, physics, cosmology, biology, paleontology), Social sciences (economy, sociology, psychology, political science, law), Humanities (linguistics, philology, art, literature, history), Applied science (medical science, informatics, space)",,,,OpenAIRE,,,oaf,Agregator,,
Semantic Scholar Academic Graph API,https://www.semanticscholar.org/product/api#Documentation,"We provide the RESTful Semantic Scholar Academic Graph (S2AG) API as a service to the global research community. The API is a reliable on-demand source of data about authors, papers, citations, venues, and more that allows you to link directly to the corresponding page on semanticscholar.org for more information. This service of the Semantic Scholar API provides utilites to help conference organizers with the problem of assigning reviewers to conference submissions.",https://www.semanticscholar.org/product/api/tutorial,https://api.semanticscholar.org/graph/v1,"HTTP, Swagger",JSON,"id,doi,archiv,pubmed,pmid,corpusid",,https://api.semanticscholar.org/license/,mixed,,,,Allen Institute for AI,,S2AG,,Agregator,,https://www.semanticscholar.org/product/api/tutorial#Bulk
{ NASA APIs },https://api.nasa.gov/,"The objective of this site is to make NASA data, including imagery, eminently accessible to application developers. This catalog focuses on broadly useful and user friendly APIs and does not hold every NASA API.",https://api.nasa.gov/,,HTTP,JSON,,"Hourly Limit: 30 requests per IP address per hour
Daily Limit: 50 requests per IP address per day Hourly Limit: 1,000 requests per hour For each API key, these limits are applied across all api.nasa.gov API requests. Exceeding these limits will lead to your API key being temporarily blocked from making further requests. The block will automatically be lifted by waiting an hour. If you need higher rate limits, contact us.",,"Natural sciences (chemistry, earth sciences, physics, cosmology, biology, paleontology), Applied science (medical science, informatics, space)",,,,National Spatial Agency,https://github.com/nasa/api-docs,,,Metacatalog,,
OpenCitations,https://opencitations.net/querying,"OpenCitations is currently managed by the Research Centre for Open Scholarly Metadata, an independent research centre within the University of Bologna. The Research Centre has an International Board drawn from leaders within the main bibliographic stakeholder communities of relevance (librarians, bibliometricians, academics, data service providers, etc.) who have shown past solid commitment to open scholarship. The statutes of the Research Centre will ensure that OpenCitations' original aim of free provision of open bibliographic and citation data, services and software is maintained, and that OpenCitations as an organization cannot in future be taken over or controlled by commercial interests, nor become involved in political, regulatory, legislative or financial lobbying of any kind.",https://opencitations.net/meta/api/v1,https://w3id.org/oc/meta/api/v1,"HTTP, SPARQL",JSON,"doi,omid,isbn",,"The data held in any of the OpenCitations datasets are made freely available under a Creative Commons public domain dedication (CC0).
The text of the web pages that comprise the OpenCitations web site is made freely available under a Creative Commons Attribution 4.0 International Public License.
The software developed by OpenCitations for implementing all the services is made freely available on GitHub under the ISC License.",,,,,Research Centre for Open Scholarly Metadata,https://github.com/opencitations/metadata/,,"dcterms, rdfs, owl, foaf","Metacatalog, Agregator",,https://opencitations.net/download
re3data.org,https://www.re3data.org/api/doc,"re3data.org supports the retrievial of its content via API. Currently the platform offers a simple open search implementation as well as a first version of a RESTful interface. Despite having HATEOAS in focus for the RESTful interface, the different APIs are versioned via URL and not via Accept-Header.",https://www.re3data.org/api/doc,https://www.re3data.org/api/,HTTP,XML,id,,"Except where otherwise noted, content on this site is licensed under a Creative Commons Attribution 4.0 International License",mixed,,,,,,,,Metacatalog,,
Digital Bodleian Search and Data,https://digital.bodleian.ox.ac.uk/developer/,"Digital Bodleian first launched in 2015 with the aim of bringing together digitized content from the Bodleian Libraries' extraordinary and rich collections into a single portal. The Bodleian Libraries have been digitizing content since the early 1990s and Digital Bodleian was and is designed to enable access to that content for the widest possible audience. Digital Bodleian quickly established itself as a key resource for research and teaching based on Bodleian Libraries' collections, and usage has steadily increased over the years since launch.",https://digital.bodleian.ox.ac.uk/developer/data/,https://digital.bodleian.ox.ac.uk/objects,"HTTP, Swagger",JSON-LD,id,,https://digital.bodleian.ox.ac.uk/terms/,CHO (Cultural Heritage Organizations),,,,The Bodleian Libraries,https://github.com/bodleian,,,Metacatalog,,
OpenAlex API,https://api.openalex.org/,"OpenAlex is a fully open catalog of the global research system. It's named after the ancient Library of Alexandria and made by the nonprofit OurResearch. The API is the primary way to get OpenAlex data. It's free and requires no authentication. OpenAlex offers an open replacement for industry-standard scientific knowledge bases like Elsevier's Scopus and Clarivate's Web of Science. Compared to these paywalled services, OpenAlex offers significant advantages in terms of inclusivity, affordability, and avaliability.
https://docs.openalex.org/",https://docs.openalex.org/,https://api.openalex.org,HTTP,JSON,id,"The API is limited to 100,000 calls per day. If you need more, simply drop us a line at support@openalex.org. There is a burst rate limit of 10 requests per second. So calling multiple requests at the same time could lead to errors with code 429. 
If you're calling the API with a list of IDs, using the OR syntax will save a lot of time and likely reduce any 429 errors. Check out our tutorial on how to do that with DOIs.","The website, API, and data snapshot are all available at no charge. The data is licensed as CC0 so it is free to use and distribute. As a nonprofit, making this data free and open is part of our mission.",mixed,,,,https://ourresearch.org/,https://github.com/ourresearch,,,Agregator,,
Europe PMC,https://europepmc.org/developers,"Europe PMC is hosted by EMBL's European Bioinformatics Institute (EMBL-EBI), an international, innovative and interdisciplinary research organisation which aims to make the world's public biological data freely available to the scientific community. Europe PMC is partnered with PubMed Central (PMC), and endorsed and supported by a group of international science funders as their repository of choice. The Europe PMC RESTful Web Service gives you access to over 33 million publications from various sources, including PubMed, Agricola, the European Patents Office (EPO) and the National Institute for Clinical Excellence (NICE). Use the Web Service to access",https://europepmc.org/developers,,"HTTP, OAI-PMH, SOAP","XML, JSON","id,pmid",These protocols provide access to Open Access content and metadata. It is not permissible to use any kind of automated process to bulk download other content from Europe PMC.,,mixed,,,,"Europe PMC is a service of the Europe PMC Funders' Group, in partnership with the European Bioinformatics Institute; and in cooperation with the National Center for Biotechnology Information at the U.S. National Library of Medicine (NCBI/NLM) . It includes content provided to the PMC International archive by participating publishers.",https://github.com/EuropePMC,,"dc, dcterms, dcmitype",Agregator,,
DOAJ API,https://doaj.org/api/v3/docs,"DOAJ is a unique and extensive index of diverse open access journals from around the world, driven by a growing community, committed to ensuring quality content is freely available online for everyone. DOAJ's mission is to increase the visibility, accessibility, reputation, usage and impact of quality, peer-reviewed, open access scholarly research journals globally, regardless of discipline, geography or language.","https://doaj.org/api/,https://doaj.org/api/v3/docs",https://doaj.org/api/,"HTTP, OAI-PMH, Swagger","XML, JSON","id,orcid,doi,issn","Is there an upload limit for uploading articles, or a rate limit?
No, there is no limit set on how many articles you can upload, but we do have a rate limit.",mixed,,,,DOAJ,https://github.com/DOAJ,,,"Metacatalog, Agregator",,,
Open Library,https://openlibrary.org/dev/docs/restful_api,"Open Library is an initiative of the Internet Archive, a 501(c)(3) non-profit, building a digital library of Internet sites and other cultural artifacts in digital form. Other projects include the Wayback Machine, archive.org and archive-it.org. Open Library is an open project: the software is open, the data are open, the documentation is open, and we welcome your contribution. Open Library offers a suite of APIs to help developers get up and running with our data. This includes RESTful APIs, which make Open Library data availabile in JSON, YAML and RDF/XML formats. There's also an earlier, now deprecated JSON API which is preserved for backward compatibility.",https://openlibrary.org/dev/docs/restful_api,,HTTP,"XML, JSON",id,,,mixed,,,,Internet Archive,https://github.com/internetarchive/openlibrary,,dc,Metacatalog,,
WorldCat Search API,https://www.oclc.org/developer/api/oclc-apis/worldcat-search-api.en.html,"The WorldCat Search API 2.0 supports much of the core functionality of the original WorldCat Search API in a streamlined JSON format. The API also allows enhanced access to local holdings record data across the cooperative, including shared print retention information. Search WorldCat and retrieve bibliographic records for cataloged items such as books, videos, music and more in WorldCat.",https://developer.api.oclc.org/wcv2,,"HTTP, SRU,Swagger","XML, JSON","oclc,isbn","We set limits on API usage that meet our typical member's needs while insuring sufficient network and server resources are available for everyone. For example, the WorldCat Search API v1 has a rolling 24 hour limit of 50,000 requests.",https://policies.oclc.org/en/copyright.html,mixed,,,,OCLC,https://github.com/OCLC-Developer-Network,,,Metacatalog,,
Exlibris Alma REST APIs,https://developers.exlibrisgroup.com/alma/apis/,"Alma REST APIs provide access to data and workflows stored in Alma. The Developer Network is your key to getting the most out of these APIs. On the following pages, you'll find documentation for each of the interfaces, including a full description of the parameters and the data objects.",https://developers.exlibrisgroup.com/alma/apis/bibs/,https://developers.exlibrisgroup.com/console/?url=/wp-content/uploads/alma/openapi/bibs.json#/Retrieve%20Bibs,"HTTP, SWORD, Swagger, SRU",JSON,id,"The APIs and API Materials are made available for use and access by Members that are customers of the relevant Ex Libris programs and services for their internal purposes and to other developers that can certify that they will not, on their own or on another party’s behalf, use or access such APIs or API Materials for any commercial purpose, including, without limitation, in connection with the marketing, sale, distribution, development or availability of any commercial third party products or services. Any use or access of the APIs or API Materials for commercial purposes or by or on behalf of third parties that are marketing, developing or distributing commercially available products or services is strictly prohibited without a separate license agreement signed by Ex Libris.
https://developers.exlibrisgroup.com/about/terms/",,mixed,,,,Clarivate (ExLibris),,,,Agregator,,
Research Organization Registry,https://ror.readme.io/docs/rest-api,"The ROR REST API allows users to retrieve, search, and filter the organizations indexed in ROR. The API is built with Django, indexing and search is enabled by Elasticsearch, and results are returned as JSON. ROR's current data structure (aka its ""metadata schema"" or ""JSON schema"") is based on Digital Science's GRID, which provided the original seed data for the registry. GRID retired its public releases as of 16 Sep 2021, and ROR began managing its data independently from GRID in March 2022. The current ROR metadata schema inherited from GRID in 2019 is now unofficially known as version 1.0. After two rounds of community feedback in 2022/2023, we are planning metadata metadata schema version 2.0 for release in late 2023. Read more about ROR's plans for metadata schema versioning. To suggest a change to the ROR data structure, please file a Schema Change Request on the ROR Roadmap -- but before you do, please see whether your desired change is already planned in ROR metadata schema 2.0.",https://ror.readme.io/docs/ror-schema-api-v2-beta,https://api.dev.ror.org/v2/,HTTP,JSON,id,"No registration is required to use the ROR API, but note that the rate limit is a maximum of 2000 requests in a 5-minute period, and API traffic can be quite heavy at popular times like midnight UTC. If you need to make more requests or want to ensure faster response times, you can also run the entire ROR API locally in Docker. See the README on the ROR API GitHub repository for instructions on running the ROR API locally.",ROR data is freely and openly available without any restrictions under the Creative Commons CC0 1.0 Universal Public Domain dedication. ROR code is openly available on Github under a MIT License.,mixed,,,,"California Digital Library, Crossref, and DataCite",https://github.com/ror-community/ror-api,ROR,,Agregator,,https://ror.readme.io/docs/data-dump
Sherpa APIs,https://v2.sherpa.ac.uk/api/,The Sherpa APIs (application programming interfaces) provide access to the functionality and datasets that Sherpa Services operate across. Swagger: https://app.swaggerhub.com/apis/gobfrey/v2.sherpa-api/2.2,https://v2.sherpa.ac.uk/api/,https://v2.sherpa.ac.uk/cgi/object_ids,"HTTP, Swagger",JSON,id,,We allow most of our website and its contents to be reused under the terms of a Creative Commons License (CC BY-NC-SA). https://www.jisc.ac.uk/website/copyright?loc=cc,,,,,JISC,,,,Agregator,,
DataCite REST API,https://support.datacite.org/docs/api,"The DataCite REST API allows any user to retrieve, query and browse DataCite DOI metadata records. In addition, DataCite Repositories can register DOIs and DataCite Members can manage Repositories and prefixes via the API. The API is generally RESTful and returns results in JSON, as the API follows the JSONAPI specification. The retrieve, query and browse functions do not require authentication, but the DataCite Member and Repository functions do require authentication with your DataCite Member or Repository ID.Other alternatives to retrieve, query and browse DataCite DOI metadata records include the DataCite OAI-PMH service and the DataCite Commons service. OAI-PMH is used primarily for bulk harvesting of metadata, and DataCite Search – which uses the DataCite REST API under the hood – provides a web interface to retrieve, query and browse DataCite metadata records. As of December 2019 the REST API is split into two versions: a Public API and a Member API. These two APIs use exactly the same URLs (starting with https://api.datacite.org), run exactly the same code, and provide exactly the same public data, the only difference being that traffic is directed to a different set of servers if users authenticate as a member. The DataCite status page page reflects this change, you can now see separate metrics (both response time and request count) for the Public API and Member API.
https://blog.datacite.org/announcing-member-api/",https://support.datacite.org/docs/api,"https://api.datacite.org/,https://api.datacite.org/dois","HTTP, OAI-PMH",JSON,doi,https://support.datacite.org/docs/apis,https://creativecommons.org/licenses/by/4.0/,mixed,,,,DataCite,https://github.com/topics/datacite?o=desc&s=updated,,,Metacatalog,,
bioRxiv API,https://api.biorxiv.org/,Preprint published article detail for specified server (bioRxiv or medRxiv).,https://api.biorxiv.org/,https://api.biorxiv.org/details/biorxiv,"HTTP, OAI-PMH","XML, JSON","doi,id",,,"Natural sciences (chemistry, earth sciences, physics, cosmology, biology, paleontology)",,,,bioRxiv,,,,Metacatalog,,
Altmetric,https://api.altmetric.com/,"Altmetric does all the heavy lifting involved in extracting, disambiguating and collating mentions of scholarly content online, allowing you to focus on the bigger picture. The Details Page API provides you with programmatic access to the metrics data associated with articles, datasets, books and many other research outputs collected by Altmetric. With technical expertise, you can create your own ways of slicing and viewing our data, which gives you the freedom to complete more complex research, ask more granular questions of our data, and build custom visualizations. The major advantage is that API calls allow for programmatic, automated data flows, so that the data can be called into your own system, and remain current. The Details Page API focuses on a subset of the data we have about research outputs and mentions. It is a very powerful tool if you have the skills and resources needed to use it. The Details Page API allows you to find out everything you need to know about an individual research output (identified by DOI, PubMed ID or other scholarly identifier) or a wider range of results when querying using one or more journal ISSNs. This API works best when you have a list of output identifiers for which you want either the count of mentions Counts Only or the full text of mentions Full Access.",https://api.altmetric.com/getting-started.html,https://api.altmetric.com/v1/doi/,HTTP,JSON,"doi,pmid,handle,arxiv,ads,ssrn,repec,isbn,id,nct_id,urn","Every day the Details Page API handles a large number of requests. To help manage the volume of these requests, limits are placed on the number of requests that can be made from a specific IP. These limits help us provide a reliable and dependable API service that serves the Altmetric community.
If you are using the API without a key you can check the X-HourlyRateLimit-Limit and X-DailyRateLimit-Limit headers for the current limits. The X-HourlyRateLimit-Remaining and X-DailyRateLimit-Remaining headers will tell you how many calls you have remaining.
When your rate limit has been exceeded, a 429 'Too many requests' error is returned by the API. When this occurs it is recommended that you examine HTTP headers above and pause requests until sufficient time has passed. If you find that you frequently hit the rate limit then you might want to consider throttling your requests or purchasing a commercial API key.",https://api.altmetric.com/licensing.html#licensing,mixed,,,,Altmetric LLC,,,,Agregator,jats,
Unpaywall,https://unpaywall.org/products/api,"An open database of 47,895,197 free scholarly articles. We harvest Open Access content from over 50,000 publishers and repositories, and make it easy to find, track, and use. The database snapshot, Simple Query Tool, REST API, and Data Feed products all return JSON-formatted data. For simplicity, that data is organized under the same schema in all cases; that schema is informally described on this page. Regardless of the source, each record returned consists of one DOI Object, containing resource metadata. Each DOI Object in turn contains a list of zero or more OA Location Objects. New fields may be added at any time. This won't be a problem for existing code in most cases since they will simply go unused, but you shouldn't rely on the number of fields being fixed.",https://unpaywall.org/products/api,https://api.unpaywall.org/v2/,HTTP,JSON,doi,"Please limit use to 100,000 calls per day. If you need faster access, you'll be better served by downloading the entire database snapshot for local access.",https://unpaywall.org/legal/terms-of-service,,,,,,,,,Agregator,,https://unpaywall.org/products/snapshot
FAIRsharing API ,https://api.fairsharing.org,The new FAIRsharing application has a REST API which offers the opportunity to both query and modify data. It's accessible to any user with an account on the system for showing basic information and for modifying any record you've created or maintain.,https://fairsharing.org/API_doc,"/fairsharing_records/,/search/fairsharing_records/ ",HTTP,JSON,"doi,id",,https://fairsharing.org/licence,,,,,,,,,,,
